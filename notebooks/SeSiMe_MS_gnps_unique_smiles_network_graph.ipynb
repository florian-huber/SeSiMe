{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeSiMe\n",
    "### Sentence/Sequence Similarity Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:  Creat graphml network file and metadata csv file for cytoscape\n",
    "Import MS data and create documents.\n",
    "\n",
    "### here: GNPS Dataset of 11134 spectra with smiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data locations\n",
    "ROOT = \"C:\\\\OneDrive - Netherlands eScience Center\\\\Project_Wageningen_iOMEGA\"\n",
    "PATH_MS_DATA = ROOT + \"\\\\Data\\\\labeled_MS_data\\\\\"\n",
    "PATH_SAVE_DATA = ROOT + \"\\\\SeSiMe\\\\data\\\\\"\n",
    "PATH_SAVE_MODEL = ROOT + \"\\\\SeSiMe\\\\models_trained\\\\\"\n",
    "PATH_SESIME = ROOT + \"\\\\SeSiMe\\\\\"\n",
    "\n",
    "PATH_NPLINKER = ROOT + \"\\\\nplinker\\\\prototype\\\\\"\n",
    "#mgf_file = PATH_MS_DATA + \"GNPSLibraries_allSMILES.mgf\"\n",
    "mgf_file = PATH_MS_DATA + \"GNPSLibraries_uniqueSMILES_withFeatureIDs.mgf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import general packages\n",
    "import sys\n",
    "sys.path.insert(0, PATH_NPLINKER)\n",
    "sys.path.insert(0, PATH_SESIME)\n",
    "\n",
    "import helper_functions as functions\n",
    "import MS_functions\n",
    "\n",
    "import numpy as np\n",
    "from metabolomics import load_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectra json file found and loaded.\n"
     ]
    }
   ],
   "source": [
    "# Import / Load data\n",
    "results_file = \"filtered_data_unique_smiles_minpeak10_loss500_2dec.json\"\n",
    "\n",
    "spectra, spectra_dict, MS_documents, MS_documents_intensity, sub_spectra_metadata = MS_functions.load_MGF_data(PATH_SAVE_DATA,\n",
    "                  mgf_file, \n",
    "                 results_file = results_file,\n",
    "                 num_decimals = 2,\n",
    "                 min_frag = 0.0, max_frag = 1000.0,\n",
    "                 min_loss = 5.0, max_loss = 500.0,\n",
    "                 min_intensity_perc = 0.01, \n",
    "                 exp_intensity_filter = 0.01,\n",
    "                 min_peaks = 10,\n",
    "                 peaks_per_mz = 15/200,\n",
    "                 peak_loss_words = ['peak_', 'loss_'], #['mz_', 'mz_'], \n",
    "                 sub_spectra = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents\n",
    "\n",
    "+ Peaks were removed using an exponential fit to the peak intensity distribution. \n",
    "+ Words were created using 2 decimals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['peak_74.73', 'peak_79.02', 'peak_89.02', 'peak_89.04', 'peak_90.05', 'peak_95.05', 'peak_98.98', 'peak_105.04', 'peak_107.05', 'peak_117.03', 'peak_118.04', 'peak_134.67', 'peak_135.05', 'peak_135.28', 'peak_136.05', 'peak_137.00', 'peak_137.15', 'peak_145.03', 'peak_147.12', 'peak_160.09', 'peak_161.08', 'peak_162.59', 'peak_163.04', 'peak_163.08', 'peak_163.29', 'peak_164.04', 'peak_165.00', 'peak_165.40', 'peak_166.30', 'peak_167.15', 'peak_168.17', 'peak_172.58', 'peak_175.08', 'peak_181.06', 'peak_229.03', 'peak_237.01', 'peak_330.10', 'peak_330.14', 'loss_92.10', 'loss_100.08', 'loss_148.05', 'loss_154.04', 'loss_156.53', 'loss_160.95', 'loss_161.96', 'loss_162.81', 'loss_163.71', 'loss_164.11', 'loss_165.07', 'loss_165.82', 'loss_166.03', 'loss_166.07', 'loss_166.52', 'loss_168.04', 'loss_169.03', 'loss_182.00', 'loss_184.08', 'loss_191.96', 'loss_192.11', 'loss_193.07', 'loss_193.84', 'loss_194.07', 'loss_194.44', 'loss_211.07', 'loss_212.08', 'loss_222.06', 'loss_224.07', 'loss_230.13', 'loss_234.07', 'loss_239.07', 'loss_240.07', 'loss_240.09', 'loss_250.09', 'loss_254.38']\n"
     ]
    }
   ],
   "source": [
    "# Have a look at how a document looks like:\n",
    "print(MS_documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switch to general SeSiMe functionality\n",
    "Once we have a corpus (e.g. through cells above), we can use SeSiMe to apply different similarity measuring methds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Similarities import SimilarityMeasures\n",
    "\n",
    "MS_measure = SimilarityMeasures(MS_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess documents...\n",
      "Number of unique words:  67455\n"
     ]
    }
   ],
   "source": [
    "MS_measure.preprocess_documents(0.2, min_frequency = 2, create_stopwords = False)\n",
    "print(\"Number of unique words: \", len(MS_measure.dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "In total it would be about 100.000 words. Many occur only once in the entire corpus and are hence filtered out (makes not sense to place them somewhere in word-space, would be arbitrary!).\n",
    "\n",
    "Few also are filtered out because they occur too often (in more than 20% of the spectra). Those words have little discriminative power and are hence ignored. Might still be worth keeping them in for comparison!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec -based approach\n",
    "### Compare different training parameters\n",
    "\n",
    "+ Create Word2Vec based document centroid vectors based on models trained using different window sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load stored word2vec model ...\n"
     ]
    }
   ],
   "source": [
    "file_model_word2vec = PATH_SAVE_MODEL + 'model_w2v_MS_gnps_uniquesmiles_d300_w300_iter100_loss500_minpeak10_dec2.model'\n",
    "MS_measure.build_model_word2vec(file_model_word2vec, size=300, window=300, \n",
    "                             min_count=1, workers=4, iter=100, \n",
    "                             use_stored_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 'words' of the given documents were found in the trained word2vec model.\n",
      "  Calculated centroid vectors for  9550  of  9550  documents. Calculated centroid vectors for  8610  of  9550  documents.Calculated distances between  9550  documents.\n"
     ]
    }
   ],
   "source": [
    "# Use peak intensities as extra weights\n",
    "MS_measure.get_vectors_centroid(extra_weights = MS_documents_intensity, tfidf_weighted=True)\n",
    "MS_measure.get_centroid_similarity(num_hits=25, method='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has calculated (cosine) distances between all spectra in an all-vs-all fashion.\n",
    "The \"num_hits\" closest candidates for each spectrum are listed in two matrices.\n",
    "\n",
    "One stores the distances, the other the respective IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graphml file and get metadata from ClassyFire csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network stored as graphml file under:  MS_word2vec_01.graphml\n"
     ]
    }
   ],
   "source": [
    "MS_functions.MS_similarity_network(MS_measure, \n",
    "                          similarity_method=\"centroid\", \n",
    "                          link_method = \"single\", \n",
    "                          filename=\"MS_word2vec_01.graphml\", \n",
    "                          cutoff = 0.7,\n",
    "                          max_links = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network stored as graphml file under:  MS_word2vec_02.graphml\n"
     ]
    }
   ],
   "source": [
    "# Compare to this one:\n",
    "MS_functions.MS_similarity_network(MS_measure, \n",
    "                                   similarity_method=\"centroid\", \n",
    "                                   link_method = \"mutual\", \n",
    "                                   filename=\"MS_word2vec_03.graphml\", \n",
    "                                   cutoff=0.5,\n",
    "                                   max_links = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = PATH_MS_DATA + \"ClassyFire_InputforCytoscape_GNPSLibraries.csv\"     \n",
    "\n",
    "import pandas as pd\n",
    "mol_classes = pd.read_csv(csvfile, delimiter='\\t')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mol_superclasses = []\n",
    "list_mol_classes = []\n",
    "list_mol_subclasses = []\n",
    "\n",
    "for spectrum in spectra:\n",
    "    subtable = mol_classes[mol_classes['inchikey'].str.contains(spectrum.metadata['inchikey'])]\n",
    "    \n",
    "    if subtable.shape[0] > 0:  # i.e. if match was found\n",
    "        list_mol_superclasses.append(subtable['superclass'].values[0])\n",
    "        list_mol_classes.append(subtable['class'].values[0])\n",
    "        list_mol_subclasses.append(subtable['subclass'].values[0])\n",
    "    else:\n",
    "        list_mol_superclasses.append('None')\n",
    "        list_mol_classes.append('None')\n",
    "        list_mol_subclasses.append('None')\n",
    "    \n",
    "# Remove nan's\n",
    "list_mol_superclasses = ['None' if x is np.nan else x for x in list_mol_superclasses]\n",
    "list_mol_classes = ['None' if x is np.nan else x for x in list_mol_classes]\n",
    "list_mol_subclasses = ['None' if x is np.nan else x for x in list_mol_subclasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv for cytoscape\n",
    "import csv\n",
    "\n",
    "csv.register_dialect('myDialect', delimiter = ';', lineterminator = '\\r\\n\\r\\n')\n",
    "filename = PATH_SESIME + \"spectra_molclasses.csv\"\n",
    "\n",
    "with open(filename, 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow([\"node;\" + \"spectrum_ID;\" + \"mol_superclass;\" + \"mol_class;\"\n",
    "                     + \"mol_subclass;\" + \"smiles;\" + \"parent_mz;\"])\n",
    "    for i, mol_class in enumerate(list_mol_classes):\n",
    "        writer.writerow([str(i) + \";\" + str(int(sub_spectra_metadata.iloc[i][1]))+ \";\" \n",
    "                         + list_mol_superclasses[i] + \";\" \n",
    "                         + mol_class + \";\" + list_mol_subclasses[i] + \";\" + spectra[i].smiles + \";\"\n",
    "                         + str(int(sub_spectra_metadata.iloc[i][3])) + \";\"])\n",
    "\n",
    "csvFile.close()\n",
    "\n",
    "# TODO: check error with csv files --> some lines start with \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
