{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Importing, first pre-processing \n",
    "Loading data, importing packages, first pre-processing steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"C:\\\\OneDrive - Netherlands eScience Center\\\\Project_Wageningen_iOMEGA\"\n",
    "PATH_MS_DATA = ROOT + \"\\\\SeSiMe\\\\data\\\\SPECTRA_grimur\\\\\"\n",
    "PATH_SAVE_MODEL = ROOT + \"\\\\SeSiMe\\\\models_trained\\\\\"\n",
    "PATH_SAVE_DATA = ROOT + \"\\\\SeSiMe\\\\data\\\\\"\n",
    "PATH_SESIME = ROOT + \"\\\\SeSiMe\\\\\"\n",
    "\n",
    "PATH_NPLINKER = ROOT + \"\\\\nplinker\\\\prototype\\\\\"\n",
    "mgf_file = PATH_MS_DATA + \"GNPSLibraries_uniqueSMILES_withFeatureIDs.mgf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general packages\n",
    "import sys\n",
    "sys.path.insert(0, PATH_NPLINKER)\n",
    "sys.path.insert(0, PATH_SESIME)\n",
    "\n",
    "import helper_functions as functions\n",
    "import MS_functions\n",
    "\n",
    "import numpy as np\n",
    "from metabolomics import load_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find file  C:\\OneDrive - Netherlands eScience Center\\Project_Wageningen_iOMEGA\\SeSiMe\\data\\ filtered_data_Grimur_minpeak10_loss500_2dec_10ppm.json\n",
      "New data from  C:\\OneDrive - Netherlands eScience Center\\Project_Wageningen_iOMEGA\\SeSiMe\\data\\SPECTRA_grimur\\  will be imported.\n",
      "  Load spectrum  3880  of  4138  spectra. 1010  of  4138  spectra."
     ]
    }
   ],
   "source": [
    "# Import / Load data\n",
    "results_file = \"filtered_data_Grimur_minpeak10_loss500_2dec_10ppm.json\"\n",
    "\n",
    "spectra, spectra_dict, MS_documents, MS_documents_intensity, spectra_metadata = MS_functions.load_MS_data(PATH_MS_DATA, PATH_SAVE_DATA,\n",
    "                 filefilter=\"*.*\", \n",
    "                 results_file = results_file,\n",
    "                 num_decimals = 2,\n",
    "                 min_frag = 0.0, max_frag = 1000.0,\n",
    "                 min_loss = 5.0, max_loss = 500.0,\n",
    "                 min_intensity_perc = 0.0,\n",
    "                 exp_intensity_filter = 0.01,\n",
    "                 min_peaks = 10,\n",
    "                 peaks_per_mz = 15/200,\n",
    "                 merge_energies = True,\n",
    "                 merge_ppm = 10,\n",
    "                 replace = 'max',\n",
    "                 peak_loss_words = ['peak_', 'loss_'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switch to general SeSiMe functionality\n",
    "Once we have a corpus (e.g. through cells above), we can use SeSiMe to apply different similarity measuring methds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Similarities import SimilarityMeasures\n",
    "MS_measure = SimilarityMeasures(MS_documents)\n",
    "MS_measure.preprocess_documents(0.2, min_frequency = 2, create_stopwords = False)\n",
    "print(\"Number of unique words: \", len(MS_measure.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train spec2vec/word2vec model and derive similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model_word2vec = PATH_SAVE_MODEL + 'model_w2v_MS_gnps_uniquesmiles_d300_w300_iter100_loss500_minpeak10_dec2.model'\n",
    "MS_measure.build_model_word2vec(file_model_word2vec, size=300, window=300, \n",
    "                             min_count=1, workers=4, iter=100, \n",
    "                             use_stored_model=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
